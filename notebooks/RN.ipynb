{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"RN.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNRM8KiaXLOoXnB7JwCQ9G1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"X7zO3isAga5e"},"source":["# Rede Neural\n","A rede neural que irá identificar se um span (conjunto de palavras) é:\n"," - um endereço ou uma localização\n"," - ou não é nenhum ponto de interesse.\n"," "]},{"cell_type":"code","metadata":{"id":"9vuI8t9gfBlS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622355489532,"user_tz":180,"elapsed":222,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"a3ff13f3-25d9-4fdf-e075-fd4c9e0300c3"},"source":["from google.colab import drive\n","from tensorflow import keras\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import text_to_word_sequence, Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import pickle\n","import spacy\n","import numpy as np\n","import math   #Se não importar o math o keras.callbacks da erro\n","from tensorboard.plugins.hparams import api as hp\n","import random\n","import re\n","# Load the TensorBoard notebook extension\n","%load_ext tensorboard\n","drive.mount('/content/drive')\n","HPARAMS = {'num_filters1': 64,\n","           'num_filters2': 64,\n","           'num_words1': 3,\n","           'num_words2': 3,\n","           'hp_dropout': 0.2,\n","           'hp_optimizer': 'adam',\n","           'dense_units': 8}"],"execution_count":23,"outputs":[{"output_type":"stream","text":["The tensorboard extension is already loaded. To reload it, use:\n","  %reload_ext tensorboard\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dSQAMV_-QNis","executionInfo":{"status":"ok","timestamp":1622355490113,"user_tz":180,"elapsed":324,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"80256f1e-0189-46a2-bdc0-969f43a77045"},"source":["cd drive/My Drive/Mestrado Unicamp/Hackaton CNJ"],"execution_count":24,"outputs":[{"output_type":"stream","text":["[Errno 2] No such file or directory: 'drive/My Drive/Mestrado Unicamp/Hackaton CNJ'\n","/content/drive/My Drive/Mestrado Unicamp/Hackaton CNJ\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1UKUikS0udBw"},"source":["## Baixando dados, tokenização, criação do word_to_index_dict"]},{"cell_type":"markdown","metadata":{"id":"o-5uAZq5vbHk"},"source":["word_to_index_dict é um dicionário que converte uma palavra para um integer que representa aquela palavra.\n","\n","word_to_index_dict_inverse faz o inverso."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3CsTjlYOure","executionInfo":{"status":"ok","timestamp":1622355494807,"user_tz":180,"elapsed":4697,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"b5484f93-71ca-4b61-970e-92ea198eb014"},"source":["max_seq_len = 20\n","with open(\"incluir_address.txt\", \"r\", encoding=\"unicode-escape\") as f:\n","  address = f.readlines()\n","with open(\"address_syntetic.txt\", \"r\", encoding=\"unicode-escape\") as f:\n","  address = address + f.readlines()\n","address = [i.replace('\\n','') for i in address]\n","address = [i.replace(',', ' , ') for i in address]\n","address = [i.replace(';', ' ; ') for i in address]\n","print('len(address) = ', len(address))\n","with open(\"incluir_not_address.txt\", \"r\", encoding=\"unicode-escape\") as f:\n","  not_address = f.readlines()\n","with open(\"not_address_syntetic.txt\", \"r\", encoding=\"unicode-escape\") as f:\n","  not_address = not_address + f.readlines()\n","not_address = [i.replace('\\n','') for i in not_address]\n","not_address = [i.replace(',', ' , ') for i in not_address]\n","not_address = [i.replace(';', ' ; ') for i in not_address]\n","print('len(not_address) = ', len(not_address))\n","\n","#make the same size\n","if len(address) > len(not_address):\n","  address = address[:len(not_address)]\n","else:\n","  not_address = not_address[:len(address)]\n","\n","lista_de_frases = address+not_address\n","vocab_size = 64730\n","tokenizer = Tokenizer(num_words=vocab_size, lower=True, split=' ',\n","                      char_level=False, oov_token=\"<UNK>\", document_count=0)\n","\n","lista_de_lista_de_palavras = [text_to_word_sequence(frase, filters = '!\"“”#$%&()*+-/:=?@[\\\\]^_`{|}~\\t\\n', split=' ') for frase in lista_de_frases]\n","\n","tokenizer.fit_on_texts([palavra for lista_de_palavras in lista_de_lista_de_palavras for palavra in lista_de_palavras])\n","word_to_index_dict = tokenizer.word_index\n","word_to_index_dict[','] = len(word_to_index_dict)\n","word_to_index_dict[';'] = len(word_to_index_dict)\n","word_to_index_dict['<PAD>'] = 0\n","print(\"len(word_to_index_dict) =\", len(word_to_index_dict))\n","#texto_lista = [[word_to_index_dict[word] for word in frase] for frase in texto_lista]"],"execution_count":25,"outputs":[{"output_type":"stream","text":["len(address) =  29745\n","len(not_address) =  33027\n","len(word_to_index_dict) = 39474\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jufe_PEowGPX"},"source":["A função _index_list_to_text transforma: array([ 0, 39, 72, 73, 74, 10, 40,  6, 25, 75], dtype=int32) em \"<PAD> ela estava aguardando impaciente a chegada de seus filhotinhos\" . Serve mais para testes."]},{"cell_type":"code","metadata":{"id":"fOptLaSHs3JZ","executionInfo":{"status":"ok","timestamp":1622355494808,"user_tz":180,"elapsed":6,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["def _index_list_to_text(index_list, word_index_inverse):\n","    return ' '.join([word_index_inverse.get(i, \"\") for i in index_list])"],"execution_count":26,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PLpAUQT3t20i"},"source":["## Preparando o dicionário e os pesos da camada densa"]},{"cell_type":"code","metadata":{"id":"yJ3A6ma1l4cy","executionInfo":{"status":"ok","timestamp":1622355494808,"user_tz":180,"elapsed":4,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["embedding_size = 50\n","embedding_file = \"glove_s50.txt\"\n","def _load_embeddings_into_memmory(embedding_file, embedding_size):\n","    embeddings_index = dict()\n","    f = open(embedding_file, encoding=\"utf8\")\n","    for line in f:\n","        try:\n","            values = line.split()\n","            word = values[0]\n","            coefs = np.asarray(values[1:], dtype='float32')\n","            embeddings_index[word] = coefs\n","        except:\n","            print(f\"Word not included:{values[0]}\")\n","    f.close()\n","    print('Loaded %s word vectors.' % len(embeddings_index))\n","    print()\n","    #Remover embeddings errados\n","    key_to_remove=[]\n","    for key,value in embeddings_index.items():\n","        if len(value)!=embedding_size:\n","            key_to_remove.append(key)\n","    for key in key_to_remove:\n","        del embeddings_index[key]\n","    print(\"Removeu os seguintes tokens errados:\", key_to_remove)\n","    return embeddings_index"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"3cHQ28xgmaZo","executionInfo":{"status":"ok","timestamp":1622355494809,"user_tz":180,"elapsed":5,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["def _add_required_tokens_to_embeddings_index(required_tokens_list, embeddings_index, embedding_size):\n","  #Inicializa os required_tokens randomicamente\n","    if required_tokens_list != []:\n","        for required_token in required_tokens_list:\n","            embeddings_index[required_token] = [random.uniform(-1,1) for iter in range(embedding_size)]\n","    return embeddings_index"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qswNWOF_nEUG","executionInfo":{"status":"ok","timestamp":1622355510332,"user_tz":180,"elapsed":15527,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"42b418be-64cf-4950-9def-61490880bff8"},"source":["embeddings_index = _load_embeddings_into_memmory(embedding_file, embedding_size)\n","embeddings_index= _add_required_tokens_to_embeddings_index(['<PAD>', '<UNK>'], embeddings_index, embedding_size)\n","print(len(embeddings_index))\n","embeddings_index['casa']"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Word not included:r$\n","Word not included:00\n","Word not included:三藏法師玄奘奉\n","Word not included:r$\n","Loaded 929594 word vectors.\n","\n","Removeu os seguintes tokens errados: ['929605', '00', '0', 'r$', '-0.307602']\n","929591\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([-8.087840e-01, -2.344940e-01,  6.837990e-01, -3.552256e+00,\n","        2.660380e-01,  1.764880e-01, -8.301800e-02, -1.756600e+00,\n","        5.187320e-01,  7.874550e-01, -2.560460e-01,  5.267100e-01,\n","        2.626010e-01,  1.581000e-02,  4.528480e-01, -4.253290e-01,\n","       -1.091950e-01, -3.496000e-02, -3.325440e-01,  1.537287e+00,\n","        3.229070e-01, -6.341390e-01,  2.590570e-01, -3.703710e-01,\n","       -5.205270e-01, -4.843610e-01, -6.838160e-01, -9.480820e-01,\n","       -4.697990e-01,  1.852468e+00,  7.642130e-01,  2.127000e-03,\n","        2.985810e-01, -8.077000e-02, -3.647550e-01,  3.420010e-01,\n","        1.744480e-01, -5.170710e-01, -9.487810e-01,  8.373230e-01,\n","       -2.660080e-01,  3.273090e-01,  4.745350e-01, -5.496020e-01,\n","        2.931430e-01,  1.284411e+00, -6.722870e-01,  2.427270e-01,\n","        9.723310e-01, -7.579990e-01], dtype=float32)"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"id":"arBWcXjzzktF"},"source":["A função _create_embedding_weights vai criar os pesos que serão usados na camada Embeddings.\n","\n","Se use_full_embeddings_index for False, os pesos só existiram para palavras que existem nas bases de treino e teste, fornecidas pelo word_to_index_dict.\n","\n","Se use_full_embeddings_index for True, todos os pesos do arquivo de embeddings serão mantidos. Mas vou criar novo word_to_index_dict, ou seja, preciso remapear x_train, x_test."]},{"cell_type":"code","metadata":{"id":"CxFB2KBDma7h","executionInfo":{"status":"ok","timestamp":1622355510333,"user_tz":180,"elapsed":4,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["def _create_embedding_weights(embedding_size, word_to_index_dict, embeddings_index, use_full_embeddings_index = False):\n","    if use_full_embeddings_index:\n","      embedding_weights = np.zeros((len(embeddings_index), embedding_size))\n","      print(embedding_weights.shape)\n","      new_word_to_index_dict = {}\n","      for i, (word, dense_vector) in enumerate(embeddings_index.items()):\n","        new_word_to_index_dict[word] = i\n","        embedding_weights[i, :] = embeddings_index[word]\n","      return embedding_weights, new_word_to_index_dict\n","\n","    else:\n","      embedding_weights = np.zeros((len(word_to_index_dict), embedding_size))\n","      print(embedding_weights.shape)\n","      for word, i in word_to_index_dict.items():\n","          try:\n","              embedding_weights[i, :] = embeddings_index[word]\n","          except KeyError:\n","              # Para os tokens que não houver peso no GLOVE, inializar randomicamente\n","              embedding_weights[i, :] = [random.uniform(-1,1) for iter in range(embedding_size)]\n","      return embedding_weights, word_to_index_dict"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IXHXn0GEsMPZ","executionInfo":{"status":"ok","timestamp":1622355512819,"user_tz":180,"elapsed":2489,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"f5fa3487-8105-432d-da50-0ae00414e6bb"},"source":["def incluir_palavras_de_reservas():\n","  with open(\"palavras_para_acrescentar.txt\", \"r\", encoding=\"utf8\") as f:\n","    palavras_para_acrescentar = f.readlines()\n","  for palavra in palavras_para_acrescentar:\n","    if not palavra in word_to_index_dict:\n","      word_to_index_dict[palavra] = word_to_index_dict['ianomamis']\n","\n","embedding_weights, word_to_index_dict = _create_embedding_weights(embedding_size, word_to_index_dict, embeddings_index, use_full_embeddings_index = True)\n","print('len(word_to_index_dict) =', len(word_to_index_dict))\n","incluir_palavras_de_reservas()\n","print('len(word_to_index_dict) =', len(word_to_index_dict))\n","\n","word_to_index_dict_inverse =  {w: k for k, w in word_to_index_dict.items()}\n","vocab_size = len(embedding_weights)\n","print('len(embedding_weights) =', len(embedding_weights))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["(929591, 50)\n","len(word_to_index_dict) = 929591\n","len(word_to_index_dict) = 930344\n","len(embedding_weights) = 929591\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Wp-OSGCOibs4","executionInfo":{"status":"ok","timestamp":1622355513369,"user_tz":180,"elapsed":553,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["pickle_file = open(\"word_to_index_dict.pkl\", \"wb\")\n","pickle.dump(word_to_index_dict, pickle_file)\n","pickle_file.close()\n","#pickle_file = open(\"word_to_index_dict.pkl\", \"rb\")\n","#dic = pickle.load(pickle_file)\n","#pickle_file.close()"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ETx38f8VEV9l","executionInfo":{"status":"ok","timestamp":1622355513370,"user_tz":180,"elapsed":4,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"85131cd8-de0c-4086-a732-66759bb251b8"},"source":["#Testando se a implementação acima está correta\n","word = '<PAD>'\n","print(embeddings_index[word])\n","embedding_weights[word_to_index_dict[word]] - embeddings_index[word]"],"execution_count":33,"outputs":[{"output_type":"stream","text":["[0.7976662943830599, 0.5847921107243181, -0.4254656528312295, -0.797669121158094, 0.5622590622047146, 0.33737460274072895, -0.34261223068389723, -0.33825808575478966, 0.3160842127751886, 0.7774339545666533, -0.1721633298249734, -0.8425803571185067, 0.9728765497400131, -0.18669337182089807, 0.3510107196855301, -0.7845197259551795, -0.9470202069467994, -0.4659581697664281, 0.3744076231554474, -0.08701405400508633, 0.671297759628471, 0.14007163312652415, 0.9228761525924829, 0.39072392678998735, 0.5026359986915532, -0.040437159890612806, 0.44246195021773715, -0.10638495977647255, -0.9695325339246492, 0.6153759378443671, -0.5636049632649585, 0.9199797302993655, 0.9351561001307185, -0.572313564155905, -0.332871870456231, 0.06913303146352634, 0.6415581514325606, -0.35474717057717053, 0.7747299330650947, 0.8059627212223202, -0.18013130863289062, -0.39306658804925054, -0.9126750056474793, -0.8037563295728058, 0.5769755031064323, -0.4104569069568922, -0.4777874554142394, -0.6145204957435861, -0.6472261671759618, 0.9383301821454615]\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"z2UWEIv7TWTi"},"source":["## Transformando as Listas de palavras em Listas de Índices e X e y"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J7YLW5l3kCsA","executionInfo":{"status":"ok","timestamp":1622355515642,"user_tz":180,"elapsed":2275,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"0574121d-85c2-4199-c666-16c3962ff306"},"source":["def prepararInput(lista_de_frases):\n","  lista_de_lista_de_palavras = [text_to_word_sequence(frase, filters = '!\"“”#$%&()*+-/:=?@[\\\\]^_`{|}~\\t\\n', split=' ') for frase in lista_de_frases]\n","  for i in range(len(lista_de_lista_de_palavras)):\n","    for j in range(len(lista_de_lista_de_palavras[i])):\n","      lista_de_lista_de_palavras[i][j] = re.sub(\"[0-9]+\", 'cinco', lista_de_lista_de_palavras[i][j])\n","\n","  lista_de_lista_de_indices = [[word_to_index_dict[palavra] if palavra in word_to_index_dict else word_to_index_dict['<UNK>'] for palavra in lista_de_palavras] for lista_de_palavras in lista_de_lista_de_palavras]\n","\n","  x = lista_de_lista_de_indices\n","\n","  x = pad_sequences(x, \n","                    maxlen=max_seq_len, \n","                    dtype='int32',\n","                    padding='pre', \n","                    truncating='pre', \n","                    value=word_to_index_dict['<PAD>'])\n","  return x\n","x = prepararInput(lista_de_frases)\n","\n","y = np.append(np.ones(int(len(x)/2)), np.zeros(int(len(x)/2)))\n","print('len(x) =', len(x))\n","print('len(y) =', len(y))\n","DATASET_SIZE = len(x)"],"execution_count":34,"outputs":[{"output_type":"stream","text":["len(x) = 59490\n","len(y) = 59490\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uEhZBytvvl2m","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622355515642,"user_tz":180,"elapsed":7,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"9b2759b0-25e9-4ab7-cbcd-91455be9eb0d"},"source":["# Testando para ver se os dados estão bem construídos\n","for i in range(20):\n","    print('data:                      ', lista_de_frases[i])\n","    print('lista_de_lista_de_palavras:', lista_de_lista_de_palavras[i])\n","    #print('lista_de_lista_de_indices: ', _index_list_to_text(lista_de_lista_de_indices[i], word_to_index_dict_inverse))\n","    print('x      :                   ', _index_list_to_text(x[i], word_to_index_dict_inverse))\n","    print()\n"],"execution_count":35,"outputs":[{"output_type":"stream","text":["data:                       Aldeia AikanÃ£ ,  na Reserva IndÃ­gena TubarÃ£o LatundÃª.\n","lista_de_lista_de_palavras: ['aldeia', 'aikanã£', ',', 'na', 'reserva', 'indã\\xadgena', 'tubarã£o', 'latundãª.']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> aldeia <UNK> , na reserva indã­gena tubarã£o <UNK>\n","\n","data:                       Reserva IndÃ­gena TubarÃ£o LatundÃª.\n","lista_de_lista_de_palavras: ['reserva', 'indã\\xadgena', 'tubarã£o', 'latundãª.']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> reserva indã­gena tubarã£o <UNK>\n","\n","data:                       Terra IndÃ­gena MequÃ©ns\n","lista_de_lista_de_palavras: ['terra', 'indã\\xadgena', 'mequã©ns']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> terra indã­gena <UNK>\n","\n","data:                       reserva indÃ­gena Alto TuriaÃ§u\n","lista_de_lista_de_palavras: ['reserva', 'indã\\xadgena', 'alto', 'turiaã§u']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> reserva indã­gena alto <UNK>\n","\n","data:                       Aldeia AikanÃ£\n","lista_de_lista_de_palavras: ['aldeia', 'aikanã£']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> aldeia <UNK>\n","\n","data:                       Reserva IndÃ­gena TubarÃ£o LatundÃª\n","lista_de_lista_de_palavras: ['reserva', 'indã\\xadgena', 'tubarã£o', 'latundãª']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> reserva indã­gena tubarã£o <UNK>\n","\n","data:                       Terra IndÃ­gena MequÃ©ns\n","lista_de_lista_de_palavras: ['terra', 'indã\\xadgena', 'mequã©ns']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> terra indã­gena <UNK>\n","\n","data:                       Reserva IndÃ­gena IgarapÃ© Lourdes\n","lista_de_lista_de_palavras: ['reserva', 'indã\\xadgena', 'igarapã©', 'lourdes']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> reserva indã­gena igarapã© lourdes\n","\n","data:                       Terra IndÃ­gena Guarani\n","lista_de_lista_de_palavras: ['terra', 'indã\\xadgena', 'guarani']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> terra indã­gena guarani\n","\n","data:                       Terra IndÃ­gena Escondido\n","lista_de_lista_de_palavras: ['terra', 'indã\\xadgena', 'escondido']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> terra indã­gena escondido\n","\n","data:                       Terra IndÃ­gena Alto do GuamÃ¡\n","lista_de_lista_de_palavras: ['terra', 'indã\\xadgena', 'alto', 'do', 'guamã¡']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> terra indã­gena alto do <UNK>\n","\n","data:                       Terra IndÃ­gena ComexatibÃ¡\n","lista_de_lista_de_palavras: ['terra', 'indã\\xadgena', 'comexatibã¡']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> terra indã­gena <UNK>\n","\n","data:                       RESERVA INDÃGENA CUMURUXATIBA\n","lista_de_lista_de_palavras: ['reserva', 'indã\\x8dgena', 'cumuruxatiba']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> reserva <UNK> cumuruxatiba\n","\n","data:                       Terra IndÃ­gena TupinambÃ¡ de OlivenÃ§a\n","lista_de_lista_de_palavras: ['terra', 'indã\\xadgena', 'tupinambã¡', 'de', 'olivenã§a']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> terra indã­gena <UNK> de <UNK>\n","\n","data:                       TupinambÃ¡\n","lista_de_lista_de_palavras: ['tupinambã¡']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <UNK>\n","\n","data:                       Reserva IndÃ­gena Parque do AripuanÃ£\n","lista_de_lista_de_palavras: ['reserva', 'indã\\xadgena', 'parque', 'do', 'aripuanã£']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> reserva indã­gena parque do <UNK>\n","\n","data:                       Reserva IndÃ­gena Yanomami\n","lista_de_lista_de_palavras: ['reserva', 'indã\\xadgena', 'yanomami']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> reserva indã­gena yanomami\n","\n","data:                       rio Uraricoera\n","lista_de_lista_de_palavras: ['rio', 'uraricoera']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> rio uraricoera\n","\n","data:                       Reserva IndÃ­gena \"Rio Branco\n","lista_de_lista_de_palavras: ['reserva', 'indã\\xadgena', 'rio', 'branco']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> reserva indã­gena rio branco\n","\n","data:                       Cacique Timborana\n","lista_de_lista_de_palavras: ['cacique', 'timborana']\n","x      :                    <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> cacique timborana\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FcCP6sqHTDDM"},"source":["## Construindo o Dataset"]},{"cell_type":"code","metadata":{"id":"de2dEgnb-Jyo","executionInfo":{"status":"ok","timestamp":1622355515643,"user_tz":180,"elapsed":6,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["\n","dataset = tf.data.Dataset.from_tensor_slices((x, y))\n","dataset = dataset.shuffle(buffer_size=DATASET_SIZE)\n","\n","train_size = int(0.8 * DATASET_SIZE)\n","val_size = int(0.10 * DATASET_SIZE)\n","test_size = int(0.10 * DATASET_SIZE)\n","\n","train_dataset = dataset.take(train_size).batch(20).prefetch(1)\n","test_dataset = dataset.skip(train_size)\n","val_dataset = dataset.skip(test_size).batch(20).prefetch(1)\n","test_dataset = dataset.take(test_size).batch(20).prefetch(1)"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EmA5PpkIJ81s","executionInfo":{"status":"ok","timestamp":1622355516010,"user_tz":180,"elapsed":371,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"b868eea7-390a-417d-bbf3-f61d3271b7ff"},"source":["# Testando para ver se o dataset foi bem construído\n","a = list(test_dataset.as_numpy_iterator())\n","batch = 0\n","for i in range(10):\n","  print('_index_list_to_text = ', _index_list_to_text(list(a[batch][0][i]), word_to_index_dict_inverse))\n","  print('y =', a[batch][1][i])"],"execution_count":37,"outputs":[{"output_type":"stream","text":["_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> rua ambrosina felix , cinco fns , barroquinha\n","y = 1.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> rua doutor dantas junior , nº cinco , itapicuru\n","y = 1.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> rua otavio dias de oliveira , sn , quadra cinco lote cinco , bairro trindade\n","y = 1.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> ideal para reprodução de vídeos para o\n","y = 0.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> rua das dalias sn , alpinópolis mg cep cinco cinco\n","y = 1.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> cinco cinco cinco cinco cinco cinco cinco cinco cinco\n","y = 0.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> data matinha\n","y = 1.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> rua sao mateus , nº cinco , terreo , ilhéus\n","y = 1.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> rua oitis , cinco , contagem mg cep cinco cinco\n","y = 1.0\n","_index_list_to_text =  <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> <PAD> rua jovelino lourenco sipriano , sn , acreúna go cep cinco cinco\n","y = 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ArypWe2QuP7D"},"source":["## Modelos"]},{"cell_type":"code","metadata":{"id":"W4CWsv86haUB","executionInfo":{"status":"ok","timestamp":1622355516010,"user_tz":180,"elapsed":6,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["def CNN_deep(vocab_size, embedding_size, embedding_weights, input_length, hparams):\n","    \n","    NUM_FILTERS1, NUM_FILTERS2,NUM_WORDS1, NUM_WORDS2,HP_DROPOUT, HP_OPTIMIZER, DENSE_UNITS = \\\n","    \"num_filters1\", \"num_filters2\", \"num_words1\", \"num_words2\", \"hp_dropout\", 'hp_optimizer', 'dense_units'\n","    \n","    inputs = keras.layers.Input(shape=(input_length,))\n","    x = keras.layers.Embedding(vocab_size,\n","                                embedding_size,\n","                                input_length=input_length,\n","                                weights=[embedding_weights],\n","                                trainable=False)(inputs)\n","    x = keras.layers.SpatialDropout1D(hparams[HP_DROPOUT])(x)\n","    x = keras.layers.Conv1D(hparams[NUM_FILTERS1], kernel_size=hparams[NUM_WORDS1],\n","                                            activation=\"relu\")(x)\n","    x = keras.layers.SpatialDropout1D(hparams[HP_DROPOUT])(x)\n","    x = keras.layers.MaxPooling1D()(x)\n","\n","    x = keras.layers.Conv1D(hparams[NUM_FILTERS2], kernel_size=hparams[NUM_WORDS1],\n","                                            activation=\"relu\")(x)\n","    x = keras.layers.SpatialDropout1D(hparams[HP_DROPOUT])(x)\n","    x = keras.layers.MaxPooling1D()(x)\n","\n","    x = keras.layers.Conv1D(hparams[NUM_FILTERS2], kernel_size=hparams[NUM_WORDS1],\n","                                            activation=\"relu\")(x)\n","    x = keras.layers.SpatialDropout1D(hparams[HP_DROPOUT])(x)\n","    x = keras.layers.MaxPooling1D()(x)\n","\n","    x = keras.layers.Conv1D(hparams[NUM_FILTERS2], kernel_size=hparams[NUM_WORDS2],\n","                                            activation=\"relu\")(x)\n","    x = keras.layers.GlobalMaxPooling1D()(x)\n","    x = keras.layers.Dense(hparams[DENSE_UNITS], activation='relu')(x)\n","    x = keras.layers.Dense(1, activation='sigmoid')(x)\n","    outputs = x\n","    model = keras.Model(inputs=inputs, outputs=outputs, name='CNN_Deep_Functional_API')\n","    return model\n","selectedModel = CNN_deep"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"FFx9581LhmPm","executionInfo":{"status":"ok","timestamp":1622355516012,"user_tz":180,"elapsed":7,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["def biLSTM(vocab_size, embedding_size, embedding_weights, input_length, hparams):\n","    \n","    NUM_FILTERS1, NUM_FILTERS2,NUM_WORDS1, NUM_WORDS2,HP_DROPOUT, HP_OPTIMIZER, DENSE_UNITS = \\\n","    \"num_filters1\", \"num_filters2\", \"num_words1\", \"num_words2\", \"hp_dropout\", 'hp_optimizer', 'dense_units'\n","    \n","    inputs = keras.layers.Input(shape=(input_length,))\n","    x = keras.layers.Embedding(vocab_size,\n","                                embedding_size,\n","                                input_length=input_length,\n","                                weights=[embedding_weights],\n","                                trainable=False)(inputs)\n","    x = keras.layers.SpatialDropout1D(hparams[HP_DROPOUT])(x)\n","\n","    x = keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True), input_shape=(200, 100))(x)\n","    x = keras.layers.GlobalMaxPooling1D()(x)\n","    x = keras.layers.Dense(hparams[DENSE_UNITS], activation='relu')(x)\n","    x = keras.layers.Dense(1, activation='sigmoid')(x)\n","    outputs = x\n","    model = keras.Model(inputs=inputs, outputs=outputs, name='biLSTM')\n","    return model\n","selectedModel = biLSTM"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"GQRoBrO1hnHH","executionInfo":{"status":"ok","timestamp":1622355516013,"user_tz":180,"elapsed":7,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["def trainer(model, train_dataset, val_dataset, hparams, max_epochs=100, verbose=True):\n","    BATCH_SIZE=16\n","    \n","    TOTAL_EPOCH_COUNT = 100\n","    PATIENCE=4\n","    LOGDIR=\"training_logs\"\n","    callbacks=[tf.keras.callbacks.TensorBoard(LOGDIR),\n","               hp.KerasCallback(LOGDIR, hparams),\n","               keras.callbacks.EarlyStopping(monitor='accuracy',\n","                                             patience=PATIENCE,\n","                                             restore_best_weights=True)]\n","    \n","    model.compile(optimizer = \"adam\", loss = 'binary_crossentropy', metrics=['accuracy'])\n","    model.summary()\n","    model.fit(train_dataset,\n","                      batch_size=BATCH_SIZE,\n","                      epochs=max_epochs,\n","                      shuffle=True,\n","                      validation_data=val_dataset,\n","                      verbose=verbose,\n","                      callbacks=callbacks)\n","    \n","    test_score, test_accuracy = model.evaluate(val_dataset, batch_size=BATCH_SIZE,verbose=0)\n","    if verbose == False:\n","        train_score, train_accuracy = model.evaluate(train_dataset, batch_size=BATCH_SIZE,verbose=0)\n","        print(f'Train score:{train_score}, Train accuracy: {train_accuracy}.')\n","        print(f'Test score:{test_score}, Test accuracy: {test_accuracy}.')\n","    return test_accuracy"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-cs9lioMuG82"},"source":["# Training and saving"]},{"cell_type":"code","metadata":{"id":"ZJpcJVAzhqwG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622356000905,"user_tz":180,"elapsed":484898,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"1512068e-70c3-4440-8be5-21efb80b9f1f"},"source":["model = selectedModel(vocab_size = vocab_size,\n","                      embedding_size = embedding_size,\n","                      embedding_weights = embedding_weights,\n","                      input_length = max_seq_len,\n","                      hparams = HPARAMS)\n","\n","trainer(model = model,\n","        train_dataset = train_dataset, \n","        val_dataset = val_dataset,\n","        hparams = HPARAMS,\n","        max_epochs = 6,\n","        verbose = True)\n","\n","#tf.saved_model.save(model,'data/models/cnn_deep_functional_api.h5',save_format=\"h5\")\n","tf.keras.models.save_model(model,'lstm_bidirectional.h5',save_format=\"h5\")\n","new_model = tf.keras.models.load_model('lstm_bidirectional.h5')\n","print('model saved')"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Model: \"biLSTM\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_2 (InputLayer)         [(None, 20)]              0         \n","_________________________________________________________________\n","embedding_1 (Embedding)      (None, 20, 50)            46479550  \n","_________________________________________________________________\n","spatial_dropout1d_1 (Spatial (None, 20, 50)            0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 20, 128)           58880     \n","_________________________________________________________________\n","global_max_pooling1d_1 (Glob (None, 128)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 8)                 1032      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 9         \n","=================================================================\n","Total params: 46,539,471\n","Trainable params: 59,921\n","Non-trainable params: 46,479,550\n","_________________________________________________________________\n","Epoch 1/6\n","2380/2380 [==============================] - 60s 24ms/step - loss: 0.0922 - accuracy: 0.9664 - val_loss: 0.0459 - val_accuracy: 0.9836\n","Epoch 2/6\n","2380/2380 [==============================] - 65s 27ms/step - loss: 0.0483 - accuracy: 0.9828 - val_loss: 0.0330 - val_accuracy: 0.9885\n","Epoch 3/6\n","2380/2380 [==============================] - 65s 27ms/step - loss: 0.0388 - accuracy: 0.9860 - val_loss: 0.0310 - val_accuracy: 0.9890\n","Epoch 4/6\n","2380/2380 [==============================] - 57s 24ms/step - loss: 0.0358 - accuracy: 0.9871 - val_loss: 0.0264 - val_accuracy: 0.9905\n","Epoch 5/6\n","2380/2380 [==============================] - 56s 23ms/step - loss: 0.0317 - accuracy: 0.9889 - val_loss: 0.0243 - val_accuracy: 0.9915\n","Epoch 6/6\n","2380/2380 [==============================] - 56s 23ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.0210 - val_accuracy: 0.9930\n","model saved\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_UZVMg_7uVnz"},"source":["# Using HParams\n","Não faz sentido ainda otimizar hiperparâmetros enquanto estivermos com acurácia de quase 100%"]},{"cell_type":"code","metadata":{"id":"l9avJARjuJRQ","executionInfo":{"status":"ok","timestamp":1622356000907,"user_tz":180,"elapsed":18,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["# Clear any logs from previous runs\n","#!rm -rf ./logs/ "],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"2eYSLDfNuQdu","executionInfo":{"status":"ok","timestamp":1622356000908,"user_tz":180,"elapsed":15,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["NUM_FILTERS1 = hp.HParam('num_filters1', hp.Discrete([64,128]))#Conforme testes, acima de 128 é melhor\n","NUM_FILTERS2 = hp.HParam('num_filters2', hp.Discrete([32,64]))\n","#Conforme testes, acima de 128 é melhor\n","#Teste com 4 ficou muito abaixo da média\n","\n","DENSE_UNITS = hp.HParam('dense_units', hp.Discrete([8, 32]))\n","NUM_WORDS1 = hp.HParam('num_words1', hp.Discrete([3]))  #Conforme testes, acima de 5 é muito ruim\n","NUM_WORDS2 = hp.HParam('num_words2', hp.Discrete([3]))\n","HP_DROPOUT = hp.HParam('hp_dropout', hp.RealInterval(0.2,0.3)) \n","#0.3 teve resultados piores no passado\n","#Com poucos parametros, 0.2 estava melhor que 0.3\n","\n","HP_OPTIMIZER = hp.HParam('hp_optimizer', hp.Discrete(['adam']))# Conforme testes, sgd é ruim,\n","#'adagrad' e parecido com ADAM\n","METRIC_ACCURACY = 'accuracy'\n","USE_SPACY_EMBEDDINGS = False\n","\n","with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n","    hp.hparams_config(\n","    hparams=[NUM_FILTERS1, NUM_FILTERS2, NUM_WORDS1, NUM_WORDS2, HP_DROPOUT, HP_OPTIMIZER, DENSE_UNITS],\n","    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n","  )\n","\n","def run(run_dir, hparams):\n","    with tf.summary.create_file_writer(run_dir).as_default():\n","        if USE_SPACY_EMBEDDINGS:\n","            model = selectedModel(embedding_size = embedding_size,\n","                              input_length = max_seq_len,\n","                              hparams = {h.name: hparams[h] for h in hparams})\n","        else:\n","            model = selectedModel(vocab_size=vocab_size,\n","                                  embedding_size = embedding_size,\n","                                  embedding_weights = tokenized_data.embedding_weights,\n","                                  input_length = max_seq_len,\n","                                  hparams = {h.name: hparams[h] for h in hparams})\n","        \n","        \n","        hp.hparams(hparams)  # record the values used in this trial\n","              \n","        test_accuracy = trainer(model = model,\n","                                x_train = tokenized_data.x_train,\n","                                y_train = tokenized_data.y_train,\n","                                x_test = tokenized_data.x_test,\n","                                y_test = tokenized_data.y_test,\n","                                hparams = hparams,\n","                                max_epochs = 100,\n","                                verbose = False)\n","        \n","        tf.summary.scalar(METRIC_ACCURACY, test_accuracy, step=1)"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"UhXUt4R5udOv","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"error","timestamp":1622356001226,"user_tz":180,"elapsed":332,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}},"outputId":"34961f6e-5fdb-47c8-deb7-1e803af603f1"},"source":["%%time\n","print(\"len(x_train)=\",len(tokenized_data.x_train))\n","print(\"len(x_test)=\",len(tokenized_data.x_test))\n","\n","session_num = 0\n","for dense_units in DENSE_UNITS.domain.values:\n","    for num_filters1 in NUM_FILTERS1.domain.values:\n","        for num_filters2 in NUM_FILTERS2.domain.values:\n","            for num_words1 in NUM_WORDS1.domain.values:\n","                for num_words2 in NUM_WORDS2.domain.values:\n","                    for hp_dropout in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n","                        for hp_optimizer in HP_OPTIMIZER.domain.values:\n","                            hparams = {\n","                                    NUM_FILTERS1: num_filters1,\n","                                    NUM_FILTERS2: num_filters2,\n","                                    NUM_WORDS1: num_words1,\n","                                    NUM_WORDS2: num_words2,\n","                                    HP_DROPOUT: hp_dropout,\n","                                    HP_OPTIMIZER: hp_optimizer,\n","                                    DENSE_UNITS: dense_units\n","                                  }\n","                            run_name = \"run-%d\" % session_num\n","                            print('--- Starting trial: %s' % run_name)\n","                            print({h.name: hparams[h] for h in hparams})\n","                            session_num += 1\n","                            \n","                            for i in range(5):\n","                                print(f\"i{i}\")\n","                                run('logs/hparam_tuning/' + run_name, hparams)\n","                            print(\"---------------------------------------------------------\")\n","                            print(\"\")\n","print(\"Training fully completed.\")"],"execution_count":44,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-44-3d68c0d2a432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'print(\"len(x_train)=\",len(tokenized_data.x_train))\\nprint(\"len(x_test)=\",len(tokenized_data.x_test))\\n\\nsession_num = 0\\nfor dense_units in DENSE_UNITS.domain.values:\\n    for num_filters1 in NUM_FILTERS1.domain.values:\\n        for num_filters2 in NUM_FILTERS2.domain.values:\\n            for num_words1 in NUM_WORDS1.domain.values:\\n                for num_words2 in NUM_WORDS2.domain.values:\\n                    for hp_dropout in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\\n                        for hp_optimizer in HP_OPTIMIZER.domain.values:\\n                            hparams = {\\n                                    NUM_FILTERS1: num_filters1,\\n                                    NUM_FILTERS2: num_filters2,\\n                                    NUM_WORDS1: num_words1,\\n                                    NUM_WORDS2: num_words2,\\n                                    HP_DROPOUT: hp_dropout,\\n                                    HP_OPTIMIZER: hp_optimizer,\\n                                    DENSE_UNITS: dense_units\\n                                  }\\n                            run_name = \"run-%d\" % session_num\\n                            print(\\'--- Starting trial: %s\\' % run_name)\\n                            print({h.name: hparams[h] for h in hparams})\\n                         ...\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tokenized_data' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"dU_VzI7RtKjG"},"source":["# Funções acessórias"]},{"cell_type":"code","metadata":{"id":"84EBpPP4pPFW","executionInfo":{"status":"aborted","timestamp":1622356001225,"user_tz":180,"elapsed":327,"user":{"displayName":"FÁBIO Collado","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ggm5ymyMNRfhc3Vkx2ap4f7ZE0USYGfzcvtJLFLBA=s64","userId":"11649123765483119065"}}},"source":["with open(\"reservas.txt\", \"r\", encoding=\"utf8\") as f:\n","  reservas = f.readlines()\n","reservas = [i.replace('\\n','') for i in reservas]\n","reservas = [i.replace('/',' ') for i in reservas]\n","reservas = [text_to_word_sequence(frase, filters = '!\"“”#$%&()*+-/:=?@[\\\\]^_`{|}~\\t\\n', split=' ') for frase in reservas]\n","new_reservas=[]\n","for reserva in reservas:\n","  new_reservas = new_reservas+reserva\n","new_reservas = list(dict.fromkeys(new_reservas))\n","with open(\"palavras_para_acrescentar.txt\", \"w\", encoding=\"utf8\") as f:\n","  for reserva in new_reservas:\n","    if not reserva in word_to_index_dict:\n","      f.write(reserva+'\\n')"],"execution_count":null,"outputs":[]}]}